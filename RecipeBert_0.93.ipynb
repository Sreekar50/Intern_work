{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 19:59:52.193508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'title': 'Simple Macaroni and Cheese', 'category': 'main-dish', 'ingredients': '1 (8 ounce) box elbow macaroni ; 1/4 cup butter ; 1/4 cup all-purpose flour ; 1/2 teaspoon salt ;   ground black pepper to taste ; 2 cups milk ; 2 cups shredded Cheddar cheese', 'directions': 'Bring a large pot of lightly salted water to a boil. Cook elbow macaroni in the boiling water, stirring occasionally until cooked through but firm to the bite, 8 minutes. Drain. Melt butter in a saucepan over medium heat; stir in flour, salt, and pepper until smooth, about 5 minutes. Slowly pour milk into butter-flour mixture while continuously stirring until mixture is smooth and bubbling, about 5 minutes. Add Cheddar cheese to milk mixture and stir until cheese is melted, 2 to 4 minutes. Fold macaroni into cheese sauce until coated.', 'prep_time': '10 mins', 'cook_time': '20 mins', 'total_time': '30 mins', 'servings': '4', 'yields': '4 servings', 'calories': '630.2', 'instructions_list': '[\\'Bring a large pot of lightly salted water to a boil. Cook elbow macaroni in the boiling water, stirring occasionally until cooked through but firm to the bite, 8 minutes.\\', \"At the same time, melt butter in a saucepan over medium heat. Add flour, salt, and pepper and stir until smooth, about 5 minutes. Pour in milk slowly, while stirring continuously. Continue to cook and stir until mixture is smooth and bubbling, about 5 minutes, making sure the milk doesn\\'t burn.\", \\'Add Cheddar cheese and stir until melted, 2 to 4 minutes.\\', \\'Drain macaroni and fold into cheese sauce until coated.\\']'}\n",
      "20 mins\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import ast\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the contents of the all.json file\n",
    "with open('Filtered_recipes.json', 'r')  as file:\n",
    "    recipes = json.load(file)\n",
    "    \n",
    "test_recipes = recipes[:2]\n",
    "\n",
    "print(len(test_recipes))\n",
    "print(test_recipes[0])\n",
    "print(test_recipes[0]['cook_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def time_to_minutes(time_str):\n",
    "    if not time_str:\n",
    "        return 0\n",
    "    time_str = time_str.lower()\n",
    "    hours = re.findall(r'(\\d+)\\s*h', time_str)\n",
    "    minutes = re.findall(r'(\\d+)\\s*m', time_str)\n",
    "    total_minutes = 0\n",
    "    if hours:\n",
    "        total_minutes += int(hours[0]) * 60\n",
    "    if minutes:\n",
    "        total_minutes += int(minutes[0])\n",
    "    return total_minutes\n",
    "\n",
    "# # Prepare data\n",
    "y = np.array([time_to_minutes(recipe[\"cook_time\"]) for recipe in recipes])\n",
    "\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recipe BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize y\n",
    "y = np.array(y)  # Ensure y is a numpy array\n",
    "y_normalized = (y - y.min()) / (y.max() - y.min())  # Min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine ingredients and instructions into a single text for each recipe\n",
    "texts = [f\"Ingredients: {recipe['ingredients']}. Instructions: {recipe['directions']}\" for recipe in recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the text\n",
    "        encodings = self.tokenizer(\n",
    "            text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"].squeeze(0),  # Remove batch dimension\n",
    "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "# Split into train and test\n",
    "recipes_train, recipes_val, labels_train, labels_val = train_test_split(texts, y_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alexdseo/RecipeBERT\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = RecipeDataset(recipes_train, labels_train, tokenizer)\n",
    "val_dataset = RecipeDataset(recipes_val, labels_val, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class RecipeBERTForRegression(nn.Module):\n",
    "    def __init__(self, base_model_name='CookBERT-checkpoint', local_files_only=True):\n",
    "        super(RecipeBERTForRegression, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(base_model_name)\n",
    "        embedding_dim = self.base_model.config.hidden_size\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(embedding_dim // 2, 1),  # Output a single regression value\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        # Get the embeddings for all tokens\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Perform mean pooling (consider the attention mask)\n",
    "        # Step 1: Multiply hidden states by attention mask to ignore padding\n",
    "        masked_hidden_states = hidden_states * attention_mask.unsqueeze(-1)  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Step 2: Sum over the sequence dimension\n",
    "        summed_hidden_states = masked_hidden_states.sum(dim=1)  # Shape: (batch_size, hidden_dim)\n",
    "        \n",
    "        # Step 3: Count non-padding tokens per example\n",
    "        non_padding_counts = attention_mask.sum(dim=1).unsqueeze(-1)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        # Step 4: Calculate the mean\n",
    "        mean_pooled_output = summed_hidden_states / non_padding_counts  # Shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Pass through the regressor\n",
    "        return self.regressor(mean_pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RecipeBERTForRegression().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{epochs}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch + 1}/{epochs}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_labels.extend(outputs.cpu().numpy())\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(all_true_labels, all_pred_labels)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}: Train Loss = {total_train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Val Loss = {total_val_loss / len(val_loader):.4f}, R² = {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
